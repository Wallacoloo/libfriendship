Retain a computation tree as in previous concepts.
Audio streams are discrete-time PCM streams - not frequency info, etc.
Each node in the stream either:
  (a) point-wise multiplies the left and right inputs.
  (b) convolves the left and right inputs.

Control signals are also PCM streams.

Limitations
------
Ideal and arbitrary filters are not inherently possible.
FIR filters can be created though.
Sounds cannot be easily reversed - system is 100% causal.

Filtering
------
For filtering, one would construct e.g. a length-4 impulse response.
This IR is then uniquely defined by its frequency response at 4 points.
For example, define the gain at f=0, f=1/6 fs, f=2/6 fs f=3/6 fs.

In particular, we can create static Lagrange interpolating polynomials for
these x values, and then mix them linearly.

For example, we have h_0[n] which has a frequency response of 1 at DC, and 0
for f=1/6 fs, 2/6 fs and 3/6 fs.
h_1[n] has freq response of 1 at f=1/6 fs, and 0 at f=0, f=2/6 fs and 3/6 fs.
And so on.

Then we have a 4-band EQ that we can mix. For example, we have G0, G1, G2, G3
(gains for each band). Then the output y[n] is:
y[n] = x[n] \conv (G0*h_0[n] + G1*h_1[n] + G2*h_2[n] + G3*h_3[n])

Notably, G0, G1, G2, G3 can be PCM streams, and this becomes:
y[n] = x[n] \conv (G0[n]*h_0[n] + G1[n]*h_1[n] + G2[n]*h_2[n] + G3[n]*h_3[n])

To achieve such things as LPF, we define some input PCM stream, C[n] (cutoff,
normalized). Then, G3[n] is defined as (e.g.) 1-C[n]^2.
This can be evaluated by:
G3[n] = 1 + -1*C[n]*C[n]
i.e. stream multiplication, with some constant streams.
G2, G1, G0 would be defined in a similar manner. The main difficulty would be
in finding suitable transform polynomials.

Primitive Signals
------
Everything can in theory be constructed from \delta[n-1] and \delta[n], as
long as we supply a way of scaling those.

More practically, allow the creation of arbitrary A*\delta[n-k] signals.
We'll also need signals that extend infinitely in the x axis (e.g. for the
filtering, G3[n] = 1+ -1*C[n]*C[n]). Additionally, the DAW will be creating
periodics. Although it could compute them manually, that's some additional
overhead and requires consistent intervention to create the next N samples.
However, signals can't be infinite-length (they couldn't be convolved
numerically!)

Additionally, for effects such as delays, we might want *sparse* signals. i.e. the signal
doesn't start until t=t0. This is especially true of input signals.

Possible primitive signal format:
a) x_in[n] = A u[n-t0] u[t1-n] cos(w*t - phi)
Or b) x_in[n] = Re{C u[n-t0] u[t1-n] exp(j*w*t)}
Either format requires 5 floats. However, these are likely to not be carried
around long, so mostly inconsequential.
(b) is preferred as it does allow each addition of like-signals in symbolic
representation (useful for potential optimizations).

c) x_in[n] = Re{C u[t1-n] exp(j*w*t)}
Emulating a start time is done by multiplying by (u[t1-n] - u[t0-n]).
Very few signals (aside from, potentially, filter coeffs) start at 0 though,
so this step would almost always then happen explicitly and just be wasteful.

d) x_in[n] = \delta[n-t0] \conv (u[L-n] Re{C exp(j*w*n)} )
+ Easier to enforce t1 >= t0 requirement. i.e. t0 >= 0, L >= 0.
+ Signals are more typically provided in start-time, length format anyway
(e.g. 8th note at beat N).
- For signals that are created incrementally (e.g. in 512-sample blocks),
the phase needs to be updated manually by the DAW.
- signals with sample freq but different start time require phase editing
  before being merged symbolically.

USE FORMAT (b) or some factory that supports multiple formats.

Obtaining filter coefficients
------
H(e^jw) = h[0] + h[1]*e^{-jw} + h[2]e^{-2jw} + ...
Therefore, let H = {H[e^j0], H[e^j2pi/L], ..., H[e^j2pi(L-1)/L]}.
Then h[n] = IDFT{H}.
The downside is that we have to specify from 0 -> 2pi for frequency,
and so we get half as many EQ bands as we would expect.

Consider the N=2 case:
H{e^j2} = h[0] + h[1]e^{-jw}
H = {H[e^j0], H[e^jpi]}
Then
H_0 = H[e^j0] =  h[0] + h[1]
H_1 = H[e^jpi] = h[0] - h[1]
Solve for h[0], h[1]:
2h[0] = H_0 + H_1
2h[1] = H_0 - H_1

Consider the Lagrange case:
1 = h_0[0] + h_0[1]
0 = h_0[0] - h_0[1]
thus, h_0[n] = [0.5, 0.5]
0 = h_1[0] + h_1[1]
1 = h_1[0] - h_1[1]
thus, h_1[n] = [0.5, -0.5]

Lagrange case for N=3:
1 = h_0[0] +   h_0[1] +   h_0[2]
0 = h_0[0] + -jh_0[1] +  -h_0[2]
0 = h_0[0] +  -h_0[1] +   h_0[2]
No solution.
Lagrange case for N=2, freqs of 0, pi/2:
1 = h_0[0] +   h_0[1]
0 = h_0[0] + -jh_0[1]
No solution.

Lagrange case for N=4 (0, pi/2, pi 3pi/2):
1 = h_0[0] +   h_0[1] +   h_0[2] +   h_0[3]
0 = h_0[0] + -jh_0[1] +  -h_0[2] +  jh_0[3]
0 = h_0[0] +  -h_0[1] +   h_0[2] +  -h_0[3]
0 = h_0[0] +  jh_0[1] +  -h_0[2] + -jh_0[3]
Thus, h_0[n] = {0.25, 0.25, 0.25, 0.25}
Furthermore, for all basis, h[1] = h[3].
0 = h_1[0] +   h_1[1] +   h_1[2] +   h_1[3]
1 = h_1[0] + -jh_1[1] +  -h_1[2] +  jh_1[3]
0 = h_1[0] +  -h_1[1] +   h_1[2] +  -h_1[3]
1 = h_1[0] +  jh_1[1] +  -h_1[2] + -jh_1[3]
h_1[n] = {0.5, 0, -0.5, 0}
0 = h_2[0] +   h_2[1] +   h_2[2] +   h_2[3]
0 = h_2[0] + -jh_2[1] +  -h_2[2] +  jh_2[3]
1 = h_2[0] +  -h_2[1] +   h_2[2] +  -h_2[3]
0 = h_2[0] +  jh_2[1] +  -h_2[2] + -jh_2[3]
h_2[n] = {0.25, -0.25, 0.25, -0.25}

Lagrange-based filters:
------
- Have very large stopband ripple.
		The N=4 case (using freqs 0, pi/2, pi, 3pi/2) has ripple of
		30% when trying to LPF from 0 to pi/2.
		N=8 case has about 25% SBR.
+ Induce NO effect (delay or phase shift) when cutoff freq = inf. (i.e. h = h0+h1+h2+... =
{1,0,0,0,...}).


Interpolation of Fixed LPFs:
------
Instead of defining filters based on the Lagrange definition,
if we have a length-4 filter, we create
h_0 = {0,0,0,0},
h_1 = LPF w/ transition at pi/3
h_2 = LPF w/ transition at 2pi/3
h_3 = 1/4*{1,0,0,0}
Then, create some interpolation function between them.

Note: stopband ripple of least-squares fit is 15% for N=4.
Interpolation method:
Let A0(c), A1(c), A2(c), A3(c) be coefficients for the corresponding h_i,
where c is cutoff frequency.
Notably, A0 doesn't matter.
A1(0) = 0
A1(pi/3) = 1
A1(2pi/3) = 0
A1(pi) = 0

A2(0) = 0
A2(pi/3) = 0
A2(2pi/3) = 1
A2(pi) = 0
...
Then solve the polynomials.

Minimization LPF:
------
define h[0] = a0 + a1*c,
h[1] = a2 + a3*c,
h[2] = a4 + a5*c,
h[3] = a6 + a7*c.
Then, solve for  a_i based on minimizing the error from a large sample of
cutoff curves.
This maps most closely to the actual operations that will be performed to
obtain coefficients from the cutoff freq.
Initial testing with degree-1 polynomials, 5-term and 3-term h[n] look
promising.


Enveloping
------
How do we create things like ADSR envelopes?

Boils down to: given a parameter P, how do we create a sloped line from (0, 0)
to (P, 1)?

Option 1: Create a fixed, infinite-length slope-1 line: (0, 0), (1, 1), ...
Then multiply it by (1/P).
Gate it by G[n] = u[P-n]..

Problems:
* cannot easily compute 1/P. Potential solution: do this in the GUI,
or via taylor approximation.
* Cannot *dynamically* create u[P-n].

Solution: have DAW be responsible for creating the envelopes.
  Drawback: New interface needed for plugins to describe envelope shape
(especially when parameterized), doesn't easily allow for e.g. routing a LFO
to an envelope length. Although this may work well for individual note
envelopes, more complicated logic may be needed for other forms of enveloping
(like what)?

Solution:
DAW sends a u[n-R] gating signal as input to plugin, specifying when a note is
released.
Plugin implements a ADR envelope as two parts: parabolic AD gated by u[n-R},
and then R portion gated by 1-u[n-R] (but then the release eventually goes
negative).

Solution:
If we had resampling, this would be a non-issue.
Resampling can [sometimes] be viewed as a series of many signal delays.
Therefore, figure out delaying & enveloping can be abstracted above that.


Delay
------
Given some parameter P, how do we delay an input signal by P samples?
Fundamentally, delays in which P changes with time disobey Time-Invariance.
Therefore there is no convolution capable of implementing this.

However, our convolutions are ALREADY non-const. e.g. we can convolve two
input signals, where these input signals are produced at whim by the DAW.

We also support parameter changes, where a convolution is an interpolation of
two different convolutions. e.g. h[k] = t*h1[k] + (1-t)*h2[k].
There can be implemented as
x[n] \conv h[n] = t*(x[n] \conv h1[n]) + (1-t)*(x[n] \conv h2[n])
Thus, the convolutions actually *are* constant.

For delays, it may be possible to *approximate*:
h[0] = (P==0)
h[1] = (P==1)
and so forth.
In particular, we could create effectively do this in the frequency domain:
h[k] = \delta[k-P] = w_L^0*exp(j*P)^0 + w_L^1*exp(j*P)^1 + w_L^2*exp(j*P)^2 + ...
One difficulty is creating `exp` function (though Taylor approximation may
actually suffice). Other difficulty lies in having to emulate complex math.
Lastly, we're limited to working precision.
In general, this is a very ugly solution.
Alternatively, we could create N polynomials with N-1 roots, sum them, and
then evaluate at P.
i.e. Q0(x) = 1/D0 * (x-1)(x-2)(...)(x-{n-1})
     Q1(x) = 1/D1 * (x-0)(x-2)(...)(x-{n-1})
and so forth. Then, Q0(0) = 1, Q1(1) = 1, and so forth.
Finally, h[0] = Q0(P), h[1] = Q1(P), ...
This is only feasible for very small n, and still quite ugly.

Alternatively, we could attempt a solution that:
1. m1[n] = delay x[n] by 1 if P%2 >= 1
2. m2[n] = delay x[n] by 2 if (P/2)%2 >= 1
3. m3[n] = delay x[n] by 4 if (P/4)%2 >= 1
...
This would likely be destroyed by error accumulation.

We could force delays to be implemented by the DAW via explicit creation of
duplicate notes. This doesn't work for delaying *portions* of a note, though.

Most DAWs use lower-sample rate channels for automation. Therefore, it's not
infeasible to create fixed delays, and have the DAW interpolate between them.


Perhaps more effective than implementing convolution as a first-class
operation, is implementing delay as a first-class operation and building
convolution from that.

In such a scenario, we would implement an operation, Y[n] = delay(x1[n], by
x2[n]). Its result would be:
  Y[n] = \sum_{k=0}^L x1[k] \conv \delta[n-x2[k]]
We're still able to group the convolutions if we can prove there are constant
regions of x2[k], however, we lose a good deal of the "linearity" advantage of
our system*.
* Not entirely: delay(x, P1+P2) = delay(delay(x, P1), P2). So we can still
  break the computation into pieces... but it's not that useful (computing
staggered delays is unlikely to be less expensive than massive delays, plus we
now have the added case of *negative* delays).
This leads to non-integral AND NEGATIVE delays though -- how do we manage?

Non-integral delays
------
1. Use an interpolation scheme. Downside: we get an implicit LPF
*2 Truncate or round. No LPF. Downside: values oscillating near k+0.5 may
create some jitter. With suitable sample rate (esp. if we oversample), jitter
is inaudible.
3. Perform all computations in integer-math. Downside: inability to ever scale
a number down.
4. Perform all computations in fraction-math, with implicit scaling by the
denominator when computing delays. Downside: added complexity, truncation
still occurs, is just masked elsewhere.
5. Perform analytically. Note that this inevitably requires evaluating
cos(cos(x)).
6. Allow each delay operation to set interpolation parameters. Downside: much
greater complexity in the engine. However, can still ultimately reduce it to a
fixed convolution. Upside: a LPF could be *twivially* implemented in this manner.
#2 seems acceptable (or, allow different host configurations).

Negative delays
------
1. Treat as no-op.
2. Introduce latency of N to allow up to N negative delay.
3. Implement #2, with N configurable. Allows for #1 or #2, and one could
distinguish between real-time and export settings.


Back to ADSR enveloping
------
Draw a line from (0,0) to (A,1) for the Attack portion.
Do this by starting with N points distributed from (0,0) to (0,1/N).
For each point i, delay by A/N*i.
Normalize the signal power by multiplying by A.
Low-pass filter the signal.

For the delay portion, draw a line from (A,1) to (A+D,S)
i.e. draw a line from (0,1) to (D,S) and delay by A.
i.e. draw a line from (0,0) to (D,S-1), delay by A & add 1.
i.e. draw a line from (0,0) to (D,1), delay by A, add 1, * by S-1.
^ The above is identical to forming the Attack line, plus arithmetic ops.

For the sustain portion, we multiply the signal by (u[n], delayed by A+D, then
multiplied by u[Rtime-n]. Note: Rtime remains +\infty until we know the release time.)
For the release portion, we apply the same process as we did at the Delay
portion.

Problem: How to handle releases *before* the AD portion of the envelope is
complete? We would extract the current envelope value at the time of release
(via multiplication by a delayed impulse) and use this as the starting value
for the release (instead of S)
